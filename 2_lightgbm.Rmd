---
title: "LightGBM"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Preparation

```{r}
# Load data
train_data <- read.csv('data_train_lasso.csv')
test_data <- read.csv('data_test_lasso.csv')

y_test <- test_data$Disease
y_test_factor <- factor(y_test, levels = c(0, 1))

# Further split train_set into training and validation sets
train_Index <- createDataPartition(
  train_data$Disease,
  p = .8,
  list = FALSE, 
  times = 1)
final_train_set <- train_data[train_Index,]
validation_set <- train_data[-train_Index,]
```


## Model Fitting

```{r}
# Load required libraries
library(lightgbm)
library(caret)
library(pROC)
library(plotROC)
library(ggplot2)
library(rms)
```


```{r}
# Convert data to LightGBM format
dtrain <- lgb.Dataset(
  data = as.matrix(final_train_set[, -1]),
  label = final_train_set$Disease
  )

dvalid <- lgb.Dataset(
  data = as.matrix(validation_set[, -1]),
  label = validation_set$Disease,
  free_raw_data = FALSE)

# Parameters for the model
params <- list(objective = "binary",
               metric = "binary_logloss",
               num_leaves = 31,
               learning_rate = 0.05,
               feature_fraction = 0.9,
               bagging_fraction = 0.8,
               bagging_freq = 5)

# Training the model with validation
lgb.model <- lgb.train(params = params,
                       data = dtrain,
                       valids = list(validation = dvalid),
                       nrounds = 1000,
                       early_stopping_rounds = 10,
                       verbose = 1)

```



```{r}
# get predictions
predictions <- predict(lgb.model, as.matrix(test_data[, -1]))

# convert probabilities in `predictions` to class labels
threshold = 0.5
class_predictions = ifelse(predictions > threshold, 1, 0)
class_predictions_factor <- factor(class_predictions)

```


## Metrics
```{r} 
# Compute ROC curve
roc_curve <- roc(y_test, predictions)
# Calculate the AUC
auc_value <- auc(roc_curve)
print(auc_value)

#######################

# Create a confusion matrix
conf_matrix <- confusionMatrix(class_predictions_factor,
                               y_test_factor)

# Print the confusion matrix
print(conf_matrix)
```


```{r}
# Prepare the data for ggplot
df_for_plot <- data.frame(D = y_test, M = predictions)

# Calculate the AUC
roc_curve <- roc(df_for_plot$D, df_for_plot$M)
auc_value <- auc(roc_curve)

# Create the ROC plot with AUC
roc_plot <- ggplot(df_for_plot, aes(m = M, d = D)) +
  geom_roc() +
  style_roc() +
  geom_text(aes(x = 0.5, y = .1, 
                label = paste("AUC =", round(auc_value, 5))), 
            size = 5)

# Plot ROC with AUC
print(roc_plot)
```


```{r}
# Prepare data for Calibration Curve
calibration_data <- data.frame(disease = test_data$Disease, predicted = predictions)

# Fit logistic regression model for calibration
calib_model <- lrm(disease ~ predicted, data=calibration_data, x=TRUE, y=TRUE)

# Plot Calibration Curve
calib_plot <- calibrate(calib_model, method="boot", B=1000)
plot(calib_plot)

```

## Feature Importance
After training a LightGBM model, you can easily extract feature importances. LightGBM provides two types of feature importance:

Gain: The improvement in accuracy brought by a feature to the branches it is on.
Split: The number of times a feature is used to split the data across all trees.




```{r}
# Compute feature importance
importance <- lgb.importance(lgb.model, percentage = TRUE)
print(importance)

# Plot feature importance
lgb.plot.importance(importance, top_n = 10, measure = "Gain")
lgb.plot.importance(importance, top_n = 10, measure = "Cover")
lgb.plot.importance(importance, top_n = 10, measure = "Frequency")

```




