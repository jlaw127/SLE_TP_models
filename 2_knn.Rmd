---
title: "KNN"
output: html_document
date: "2023-11-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Preparation
```{r}
# Load data
train_data <- read.csv('data/data_train_lasso.csv')
test_data <- read.csv('data/data_test_lasso.csv')

actual_values <- test_data$disease
```

## Model Fitting

```{r}
# Load required libraries
library(class)
library(caret)
library(Metrics)
library(pROC)
library(plotROC)
library(ggplot2)
library(rms)
```


```{r}
## this function is to extract the names of numeric predictors
extract_numeric <- function(data) {
  numeric_cols <- c()
  
  for (predictor in names(data)) {
    if (is.numeric(data[[predictor]]) && 
        all(data[[predictor]] %in% c(0, 1))) {
      next
    } else {
      numeric_cols <- c(numeric_cols, predictor)
    }
  }
  return(numeric_cols)
}

```


```{r}
# separate numeric and binary predictors
train_data_numeric <- train_data[, extract_numeric(train_data)]
test_data_numeric <- test_data[, extract_numeric(test_data)]

# Convert column names to indices
numeric_col_indices <- match(extract_numeric(train_data), names(train_data))

train_data_binary <- train_data[, -numeric_col_indices]
test_data_binary <- test_data[, -numeric_col_indices]
```



```{r}
# Scale the training data (subtracts the mean and divides by the standard deviation, resulting in a dataset with a mean of 0 and a standard deviation of 1 for each column).
train_data_scaled <- scale(train_data_numeric)

# Calculate the mean and standard deviation of the training data
train_means <- attr(train_data_scaled, "scaled:center")
train_sds <- attr(train_data_scaled, "scaled:scale")

# Scale the test data using the training data parameters
test_data_scaled <- scale(test_data_numeric,
                          center = train_means,
                          scale = train_sds)

# Combine scaled numeric and binary features
train_combined <- cbind(train_data_binary, train_data_scaled)
test_combined <- cbind(test_data_binary, test_data_scaled)
```


```{r}
# convert `disease` to a factor
train_combined$disease <- factor(train_combined$disease,
                                 levels = c(0, 1),
                                 labels = c("NoDisease", "Disease"))
test_combined$disease <- factor(test_combined$disease,
                                levels = c(0, 1),
                                labels = c("NoDisease", "Disease"))

actual_values_factor <- test_combined$disease
```



```{r}
train_control <- trainControl(method="cv", number=10, 
                              summaryFunction=twoClassSummary, 
                              classProbs=TRUE, # Required for AUC calculation
                              savePredictions=TRUE)

# Define a grid to search for k
grid <- expand.grid(k = seq(1, 24, 1))


# Train the model using AUC as the metric
knn_fit <- train(disease ~ ., 
                 data=train_combined,
                 method="knn", 
                 metric="ROC", 
                 trControl=train_control,
                 tuneGrid=grid
                 )

# Print the results
print(knn_fit)
```

```{r}
# Predicted probabilities on the test set
predictions <- predict(knn_fit, newdata = test_combined, type = "prob")[, "Disease"]


# Convert probabilities to class labels based on the threshold
threshold = 0.5
knn_class_predictions <- ifelse(predictions > threshold, "Disease", "NoDisease")
predictions_factor <- factor(knn_class_predictions, levels = c("NoDisease", "Disease"))

```


## Metrics
```{r} 
# Compute ROC curve
roc_curve <- roc(actual_values, predictions)

# Calculate the AUC
auc_value <- auc(roc_curve)
print(auc_value)

# Create a confusion matrix
conf_matrix <- confusionMatrix(predictions_factor, actual_values_factor)

# Print the confusion matrix
print(conf_matrix)

```



```{r}
# Prepare the data for ggplot
df_for_plot <- data.frame(
  D = actual_values,
  M = predictions
)

# Create the ROC plot with AUC
roc_plot <- ggplot(df_for_plot, aes(m = M, d = D)) +
  geom_roc() +
  style_roc() +
  geom_text(aes(x = 0.5,
                y = .1, 
                label = paste("AUC = ", round(auc_value, 4))), 
            size = 5)

# Plot ROC with AUC
print(roc_plot)


# Calibration curve might not be applicable for KNN as it doesn't output probabilities
```




## Permutation Feature Importance


```{r}
library(randomForest)

# Permutation feature importance
set.seed(2023) # for reproducibility
importance_results <- varImp(knn_fit, test_combined, useModel = TRUE)

print(importance_results)


```





